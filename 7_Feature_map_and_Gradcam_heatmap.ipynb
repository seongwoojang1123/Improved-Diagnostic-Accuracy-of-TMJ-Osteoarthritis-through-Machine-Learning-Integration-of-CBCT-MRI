{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPSVnKQnTzeQuVMdsFArdXJ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/seongwoojang1123/Improved-Diagnostic-Accuracy-of-TMJ-Osteoarthritis-through-Machine-Learning-Integration-of-CBCT-MRI/blob/main/7_Feature_map_and_Gradcam_heatmap.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ===================== Unified Verification Script =====================\n",
        "# - Grad-CAM (hookless) + scores\n",
        "# - Feature maps @ conv=CONV_IDX, pre-/post-ReLU capture\n",
        "# - Sparsity: pre_sign, pre_eps, post_zero, post_eps (표/검증)\n",
        "# ======================================================================\n",
        "import os, torch, numpy as np, cv2\n",
        "from PIL import Image\n",
        "from torchvision import models, transforms\n",
        "from torch import nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "# ---------------- Config ----------------\n",
        "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "IMG_SIZE = 140\n",
        "NUM_CLASSES = 4\n",
        "USE_NORMALIZE = True   # <-- ImageNet 가중치/학습 체계 맞추려면 True 권장\n",
        "CKPT_PATH = None       # <-- 파인튜닝 가중치 있으면 경로 지정\n",
        "CONV_IDX = 0           # <-- 스윕 결과로 확정한 conv index\n",
        "EPS = 1e-6             # <-- ε-zero 기준\n",
        "SAVE_TILES = True\n",
        "TILES_DIR = \"/content/drive/MyDrive/TMJ OA/FeatureMaps_Verify\"\n",
        "os.makedirs(TILES_DIR, exist_ok=True)\n",
        "\n",
        "images = {\n",
        "    # CBCT\n",
        "    \"CBCT1_Rt\": \"/content/drive/MyDrive/TMJ OA/학습_data_1,3(crop)/test_data/Rt_OA/20138975 1.JPG\",\n",
        "    \"CBCT3_Lt\": \"/content/drive/MyDrive/TMJ OA/학습_data_1,3(crop)/test_data/Lt_OA/20188759 3.JPG\",\n",
        "    \"CBCT2_Rt\": \"/content/drive/MyDrive/TMJ OA/학습_data_2,4(crop)/test_data/Rt_OA/20138975 2.JPG\",\n",
        "    \"CBCT4_Lt\": \"/content/drive/MyDrive/TMJ OA/학습_data_2,4(crop)/test_data/Lt_OA/20252473 4.JPG\",\n",
        "    # MRI\n",
        "    \"MRI1_Rt\":  \"/content/drive/MyDrive/TMJ OA/학습_data_MRI_1,2/test_data/Rt_OA/20123901 1 M.jpg\",\n",
        "    \"MRI2_Lt\":  \"/content/drive/MyDrive/TMJ OA/학습_data_MRI_1,2/test_data/Lt_OA/20123901 2 M.jpg\",\n",
        "    \"MRI3_Rt\":  \"/content/drive/MyDrive/TMJ OA/학습_data_MRI_3,4/test_data/Rt_OA/20123901 3 M.jpg\",\n",
        "    \"MRI4_Lt\":  \"/content/drive/MyDrive/TMJ OA/학습_data_MRI_3,4/test_data/Lt_OA/20131063 4 M.jpg\",\n",
        "}\n",
        "\n",
        "# --------------- Transforms ---------------\n",
        "trns = [transforms.Resize((IMG_SIZE, IMG_SIZE)), transforms.ToTensor()]\n",
        "if USE_NORMALIZE:\n",
        "    trns.append(transforms.Normalize([0.485,0.456,0.406],[0.229,0.224,0.225]))\n",
        "transform_eval = transforms.Compose(trns)\n",
        "def load_rgb(p): return Image.open(p).convert(\"RGB\")\n",
        "\n",
        "# --------------- Model --------------------\n",
        "def disable_inplace_relu(model: nn.Module):\n",
        "    for m in model.modules():\n",
        "        if isinstance(m, nn.ReLU):\n",
        "            m.inplace = False\n",
        "\n",
        "def build_model():\n",
        "    m = models.vgg16(weights=models.VGG16_Weights.IMAGENET1K_V1)\n",
        "    # 분류기 구조가 다르면 아래를 활성화하고 CKPT 불러오기\n",
        "    # in_f = m.classifier[-1].in_features\n",
        "    # m.classifier[-1] = nn.Linear(in_f, NUM_CLASSES)\n",
        "    if CKPT_PATH and os.path.isfile(CKPT_PATH):\n",
        "        state = torch.load(CKPT_PATH, map_location=DEVICE)\n",
        "        m.load_state_dict(state, strict=False)\n",
        "    disable_inplace_relu(m)  # Grad 안정성\n",
        "    return m.to(DEVICE).eval()\n",
        "\n",
        "model = build_model()\n",
        "features: nn.Sequential = model.features\n",
        "\n",
        "# conv 이후 첫 ReLU 찾기\n",
        "def find_relu_after_conv(seq: nn.Sequential, conv_idx: int) -> int:\n",
        "    n = len(seq)\n",
        "    for j in range(conv_idx+1, n):\n",
        "        if isinstance(seq[j], nn.ReLU):\n",
        "            return j\n",
        "    raise RuntimeError(f\"Conv idx {conv_idx} 뒤 ReLU 없음\")\n",
        "RELU_IDX = find_relu_after_conv(features, CONV_IDX)\n",
        "\n",
        "# ---- pre/post ReLU 정확 캡처 훅 ----\n",
        "class PrePostTap:\n",
        "    def __init__(self, relu_mod: nn.Module):\n",
        "        self.pre = None\n",
        "        self.post = None\n",
        "        self.h1 = relu_mod.register_forward_pre_hook(self._pre)\n",
        "        self.h2 = relu_mod.register_forward_hook(self._post)\n",
        "    def _pre(self, module, inputs):\n",
        "        self.pre = inputs[0]  # Tensor (B,C,H,W) - 그래프 필요 X\n",
        "    def _post(self, module, inputs, output):\n",
        "        self.post = output    # Tensor (B,C,H,W)\n",
        "    def close(self):\n",
        "        self.h1.remove(); self.h2.remove()\n",
        "\n",
        "tap = PrePostTap(features[RELU_IDX])\n",
        "\n",
        "# --------------- Grad-CAM (hookless) ---------------\n",
        "class GradCAM_NoBwdHook:\n",
        "    def __init__(self, model, target_layer):\n",
        "        self.model = model\n",
        "        self.target_layer = target_layer\n",
        "        self.fmaps = None\n",
        "        self.h = target_layer.register_forward_hook(self._save)\n",
        "    def _save(self, m, i, o):\n",
        "        self.fmaps = o\n",
        "    def __call__(self, x, target_category=None):\n",
        "        logits = self.model(x)\n",
        "        if target_category is None:\n",
        "            target_category = torch.argmax(logits, dim=1).item()\n",
        "        loss = logits[0, target_category]\n",
        "        grads = torch.autograd.grad(loss, self.fmaps, retain_graph=True, allow_unused=True)[0]\n",
        "        if grads is None:\n",
        "            # 레이어를 경유하지 않은 경우 대비\n",
        "            grads = torch.zeros_like(self.fmaps)\n",
        "        weights = grads.mean(dim=(2,3), keepdim=True)  # (1,C,1,1)\n",
        "        cam = (weights * self.fmaps).sum(dim=1)        # (1,H,W)\n",
        "        cam = F.relu(cam)\n",
        "        cam = cam[0]\n",
        "        cam = (cam - cam.min()) / (cam.max() + 1e-8)\n",
        "        return cam.detach().cpu().numpy()\n",
        "    def close(self):\n",
        "        self.h.remove()\n",
        "\n",
        "# 마지막 conv 찾기\n",
        "def find_last_conv(m: nn.Module):\n",
        "    last = None\n",
        "    for mm in m.modules():\n",
        "        if isinstance(mm, nn.Conv2d):\n",
        "            last = mm\n",
        "    return last\n",
        "target_layer = find_last_conv(model)\n",
        "camper = GradCAM_NoBwdHook(model, target_layer)\n",
        "\n",
        "# --------------- Sparsity variants ---------------\n",
        "def sparsity_metrics(pre: torch.Tensor, post: torch.Tensor, eps=EPS):\n",
        "    # pre/post: (1,C,H,W) torch\n",
        "    pre_np  = pre.detach().cpu().numpy()[0]\n",
        "    post_np = post.detach().cpu().numpy()[0]\n",
        "    C, H, W = pre_np.shape\n",
        "    def mean_ratio(arr, cond):\n",
        "        return float(np.mean([cond(arr[c]).mean() for c in range(arr.shape[0])]))\n",
        "    pre_sign  = mean_ratio(pre_np,  lambda x: (x <= 0))\n",
        "    pre_eps   = mean_ratio(pre_np,  lambda x: (np.abs(x) <= eps))\n",
        "    post_zero = mean_ratio(post_np, lambda x: (x == 0))\n",
        "    post_eps  = mean_ratio(post_np, lambda x: (x <= eps))\n",
        "    return pre_sign, pre_eps, post_zero, post_eps\n",
        "\n",
        "# --------------- Overlay util ---------------\n",
        "def overlay_on_rgb(rgb_uint8, cam_hw, alpha=0.45):\n",
        "    H, W, _ = rgb_uint8.shape\n",
        "    cam_resized = cv2.resize((cam_hw*255).astype(np.uint8), (W, H))\n",
        "    heat = cv2.applyColorMap(cam_resized, cv2.COLORMAP_JET)      # BGR\n",
        "    base = cv2.cvtColor(rgb_uint8, cv2.COLOR_RGB2BGR)\n",
        "    return (alpha*heat + (1-alpha)*base).clip(0,255).astype(np.uint8)\n",
        "\n",
        "def save_tiles(chw: np.ndarray, save_path: str, rows=5, cols=20, max_tiles=100):\n",
        "    C,H,W = chw.shape\n",
        "    tiles = min(max_tiles, C)\n",
        "    import matplotlib.pyplot as plt\n",
        "    fig = plt.figure(figsize=(cols*0.9, rows*0.9))\n",
        "    fig.subplots_adjust(left=0, right=1, bottom=0, top=1, hspace=0.05, wspace=0.05)\n",
        "    for j in range(tiles):\n",
        "        ax = fig.add_subplot(rows, cols, j+1); ax.imshow(chw[j]); ax.axis(\"off\")\n",
        "    os.makedirs(os.path.dirname(save_path), exist_ok=True)\n",
        "    plt.savefig(save_path, dpi=150, bbox_inches=\"tight\"); plt.close(fig)\n",
        "\n",
        "# --------------- Run ---------------\n",
        "rows = []\n",
        "for alias, p in images.items():\n",
        "    assert os.path.isfile(p), f\"파일 없음: {p}\"\n",
        "    rgb = load_rgb(p)\n",
        "    x = transform_eval(rgb).unsqueeze(0).to(DEVICE)\n",
        "\n",
        "    # 1) Grad-CAM\n",
        "    with torch.no_grad():\n",
        "        logits = model(x)\n",
        "        pred_id = int(torch.argmax(logits, dim=1).item())\n",
        "    cam = camper(x, target_category=pred_id)\n",
        "\n",
        "    # 2) pre/post feature maps @ conv=CONV_IDX (via ReLU hooks)\n",
        "    _ = model(x)  # forward once to fill taps\n",
        "    pre  = tap.pre   # (1,C,H,W) torch\n",
        "    post = tap.post  # (1,C,H,W) torch\n",
        "    assert pre is not None and post is not None, \"pre/post 캡처 실패\"\n",
        "\n",
        "    # 3) Sparsity (4종)\n",
        "    s_pre_sign, s_pre_eps, s_post_zero, s_post_eps = sparsity_metrics(pre, post, eps=EPS)\n",
        "\n",
        "    # 4) 저장(옵션)\n",
        "    if SAVE_TILES:\n",
        "        pre_np = pre.detach().cpu().numpy()[0]\n",
        "        save_path = os.path.join(TILES_DIR, f\"{alias}_conv{CONV_IDX}_pre_t{IMG_SIZE}_preSign{ s_pre_sign:.4f}.png\")\n",
        "        save_tiles(pre_np, save_path, rows=5, cols=20, max_tiles=100)\n",
        "\n",
        "    # 5) 기록\n",
        "    rgb_u8 = np.array(rgb.resize((IMG_SIZE, IMG_SIZE)), dtype=np.uint8)\n",
        "    overlay_bgr = overlay_on_rgb(rgb_u8, cam, alpha=0.45)\n",
        "    cam_path = os.path.join(TILES_DIR, f\"{alias}_cam_pred{pred_id}.png\")\n",
        "    cv2.imwrite(cam_path, overlay_bgr)\n",
        "\n",
        "    rows.append({\n",
        "        \"alias\": alias,\n",
        "        \"pred\": pred_id,\n",
        "        \"pre_sign\":  s_pre_sign,\n",
        "        \"pre_eps\":   s_pre_eps,\n",
        "        \"post_zero\": s_post_zero,\n",
        "        \"post_eps\":  s_post_eps,\n",
        "        \"cam_path\":  cam_path\n",
        "    })\n",
        "\n",
        "camper.close(); tap.close()\n",
        "\n",
        "# --------------- Report ---------------\n",
        "try:\n",
        "    import pandas as pd\n",
        "    df = pd.DataFrame(rows)\n",
        "    # 간단한 해석 힌트 출력\n",
        "    print(df.to_string(index=False))\n",
        "    print(\"\\n[Hint]\")\n",
        "    print(\" - pre_sign≈0.4~0.5, post_zero≈0.6~0.9면: post-ReLU sparsity가 훨씬 큼(정상).\")\n",
        "    print(\" - pre_eps는 ε 설정(EPS) 민감. 시각적 착시는 imshow scaling 영향 가능.\")\n",
        "    print(f\" - Normalize={'ON' if USE_NORMALIZE else 'OFF'}, Conv idx={CONV_IDX}, ε={EPS}\")\n",
        "except Exception:\n",
        "    for r in rows: print(r)\n"
      ],
      "metadata": {
        "id": "3yK5SGD9S9xB"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}